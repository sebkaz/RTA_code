{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dane i ich modele przetwarzania\n",
    "## 1.1 Dane w pythonie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klient = [38, 'Kawaler',1, 56.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(klient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3]\n",
    "b = [4,5,6]\n",
    "print(f\"a+b: {a+b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(a*b)\n",
    "except TypeError:\n",
    "    print(\"operacja niezdefiniowana\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "aa = np.array([1,2,3])\n",
    "bb = np.array([4,5,6])\n",
    "\n",
    "type(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"aa+bb: {aa+bb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(aa*bb)\n",
    "except TypeError:\n",
    "    print(\"operacja niezdefiniowana\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(range(4))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([range(4),range(4)])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.precision',2)\n",
    "\n",
    "df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                  columns= iris['feature_names'] + ['target'])\n",
    "                  \n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nowa kolumna\n",
    "df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usuniecie kolumny\n",
    "df = df.drop(columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pierwsze wiersze\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ostatnie wiersze\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podstawowe informacje\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podstawowe statystyki \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtrowanie danych\n",
    "X = df.iloc[:100,[0,2]].values \n",
    "# pierwsze sto wierszy + kolumna 0 i 2, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# values- zamienia DataFrame na np.array\n",
    "y = df.iloc[:100,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unikalne wartosci\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# przetwarzanie warunkowe\n",
    "y = np.where(y == 'setosa',-1,1)\n",
    "X_iris, y_iris = X, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:50,0],X[:50,1],color='red', marker='o',label='setosa')\n",
    "plt.scatter(X[50:100,0],X[50:100,1],color='blue', marker='x',\n",
    "label='versicolor')\n",
    "plt.xlabel('sepal length (cm)')\n",
    "plt.ylabel('petal length (cm)')\n",
    "plt.legend(loc='upper left')\n",
    "# plt.savefig('rys1_1.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train),(X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "# wybierz trojke\n",
    "thress = (path/'train'/'3').ls().sorted()\n",
    "im3_path = thress[1]\n",
    "im3 = Image.open(im3_path)\n",
    "# zapisz obraz jako tensor i wytnij czesc\n",
    "im3_t = tensor(im3)[4:15,4:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im3_df = pd.DataFrame(im3_t)\n",
    "im3_df.style.set_properties(**{'font-size':'6pt'})\\\n",
    ".background_gradient('Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "(X_train, y_train),(X_test, y_test) = cifar10.load_data()\n",
    "# rozmiar \n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "skalar = np.array(5)\n",
    "print(skalar.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wektor_1d = np.array([3, 5, 7])\n",
    "print(wektor_1d.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macierz_2d = np.array([[1,2],[3,4]])\n",
    "print(macierz_2d.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "a = torch.tensor([1,2,3])\n",
    "b = torch.tensor([3,4,5])\n",
    "c = a+b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.tensor([[1,2,3],[3,4,5]])\n",
    "d.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "x = torch.tensor([[1,2,3],[4,5,6]], device=device)\n",
    "x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podłączenie do Apache Spark\n",
    "\n",
    "Sprawdź rozdział 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/Users/air/Desktop/spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext(master='local[*]', appName=\"book app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pierwszy element\n",
    "rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pierwsze dwa elementy\n",
    "rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losowe elementy v1\n",
    "rdd.takeSample(True,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losowe elementy v2\n",
    "rdd.takeSample(False,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.reduce(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = rdd.map(lambda x: x*x)\n",
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd3 = rdd.map(lambda x: [x,x])\n",
    "rdd3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd4 = rdd.flatMap(lambda x: [x,x])\n",
    "rdd4.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.parallelize(range(20)) \\\n",
    ".map(lambda x: x * 2) \\\n",
    ".filter(lambda x: x != 2) \\\n",
    ".reduce(lambda x,y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file example.txt\n",
    "first \n",
    "second line \n",
    "the third line \n",
    "then a fourth line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rdd = sc.textFile('example.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rdd.first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rdd.takeSample(True,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rdd.map(lambda line: line.split()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nasza_fun(line):\n",
    "    return line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rdd.map(nasza_fun).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "sc.textFile(\"example.txt\") \\\n",
    ".map(lambda x: re.findall(r\"[a-z']+\", x.lower())) \\\n",
    ".flatMap(lambda x: [(y, 1) for y in x]) \\\n",
    ".reduceByKey(lambda x,y: x + y) \\\n",
    ".collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "requests.get('https://sebastianzajac.pl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def pobierz_info_slowa(slowo):\n",
    "  language = 'en-gb'\n",
    "  headers = {\"app_id\":\"c7f6d128\",\n",
    "             \"app_key\":\"73ea2ed8109721300050137e74044fa6\"}\n",
    "  url_1 = \"https://od-api.oxforddictionaries.com:443/api/v2/entries/\"\n",
    "  url = f\"{url_1}{language}/{slowo.lower()}\"\n",
    "  return requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odp = pobierz_info_slowa('streaming')\n",
    "print(odp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odp.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('newApp').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_rdd = sc.parallelize([odp.text])\n",
    "df_sp = spark.read.json(json_rdd)\n",
    "df_sp.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"cogent\", \"digress\", \"tangible\",\n",
    "\"diligent\", \"mellifluous\", \"obscure\", \"intelligible\"]\n",
    "lista_odp = [pobierz_info_slowa(word).text for word in words]\n",
    "json_rdd = sc.parallelize(lista_odp)\n",
    "json_df = spark.read.json(json_rdd)\n",
    "json_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_df.select('metadata.*').printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json1 = \"\"\"\n",
    "{\n",
    "\"num\": [1,2,3,4]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.json(sc.parallelize([json1]))\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "df1.select(explode('num').alias('number')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_df.createOrReplaceTempView('slownik')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_df = spark.sql(\"\"\"select id as word, \n",
    "a.language\n",
    "from slownik\n",
    "lateral view outer explode(results)tmp1 as a\n",
    "\"\"\")\n",
    "flat_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_df2 = spark.sql(\"\"\"select id as word, \n",
    "a.language, b\n",
    "from slownik\n",
    "lateral view outer explode(results)tmp1 as a\n",
    "lateral view outer explode(a.lexicalEntries)tmp2 as b\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_df3 = spark.sql(\"\"\"select id as word, \n",
    "a.language, definitions as definition,\n",
    "examples.text as example\n",
    "from slownik\n",
    "lateral view outer explode(results)tmp1 as a\n",
    "lateral view outer explode(a.lexicalEntries)tmp2 as b\n",
    "lateral view outer explode(b.entries)tmp3 as c\n",
    "lateral view outer explode(c.senses)tmp4 as d\n",
    "lateral view outer explode(d.definitions)tmp5 as definitions\n",
    "lateral view outer explode(d.examples)tmp6 as examples\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Żródła i przechowywanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///irysy.db')\n",
    "# zapis ramki do bazy SQL\n",
    "df.to_sql('dane', con=engine, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = engine.execute(\"SELECT * FROM dane\").fetchall()\n",
    "df2 = pd.DataFrame(a, columns=df.columns)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "person = '{\"name\": \"Alice\", \"languages\": [\"English\", \"French\"]}'\n",
    "person_dict = json.loads(person)\n",
    "\n",
    "print( person_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(person_dict['languages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file test.json\n",
    "{\"name\": \"Alice\", \"languages\": [\"English\", \"French\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('person.json', 'w') as json_file:\n",
    "    json.dump(person_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X, y = datasets.make_classification(n_samples=10**4,\n",
    "n_features=20, n_informative=2, n_redundant=2)\n",
    "                                    \n",
    "train_samples = 7000\n",
    "\n",
    "X_train = X[:train_samples]\n",
    "X_test = X[train_samples:]\n",
    "y_train = y[:train_samples]\n",
    "y_test = y[train_samples:]\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', \"wb\") as picklefile:\n",
    "    pickle.dump(rfc, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl',\"rb\") as picklefile:\n",
    "    model = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.joblib', \"wb\") as jobf:\n",
    "    dump(rfc, jobf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.joblib',\"rb\") as jobf:\n",
    "    model = load(jobf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Dane i Metadane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane = {'temp':[15.2, 10, 13, 10, 12, 10],\n",
    "        'deszcz':[2.5, 0.2, 0.6, 0.3, 1.8, 0.2]}\n",
    "df = pd.DataFrame(dane)\n",
    "df.index = pd.DatetimeIndex(['2021-10-01', '2021-10-02',\n",
    "    '2021-10-03', '2021-10-04', '2021-10-05', '2021-10-06'], name=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dane = {'czas_zapisu': '2021-10-10T10:10:59',\n",
    "'user':'Sebastian Zajac', 'wsp':'52.143 N, 21.1554 E'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dane_key = 'pogoda.iot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_A = pa.Table.from_pandas(df)\n",
    "print(tabela_A.schema.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_json = json.dumps(meta_dane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "istniejace_metadane = tabela_A.schema.metadata\n",
    "all_metadane = {meta_dane_key.encode() : meta_json.encode(),\n",
    "**istniejace_metadane}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_A_md = tabela_A.replace_schema_metadata(all_metadane)\n",
    "pq.write_table(tabela_A_md, 'przyklad.parquet',\n",
    "compression='GZIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela = pq.read_table('przyklad.parquet')\n",
    "df2 = tabela.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moje_meta_dane = tabela.schema.metadata[meta_dane_key.encode()]\n",
    "m_m_d = json.loads(moje_meta_dane)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Obiektowośc Pythona a dane\n",
    "\n",
    "### 1.5.1. Klasa 0 - Pusta klasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moja_funkcja():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nazwa(object):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Nazwa()\n",
    "b = Nazwa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[Nazwa() for x in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'napis'.__dir__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.2. Klasa 1 - rzut kością"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "class Kosc(object):\n",
    "    \"\"\"\n",
    "    Klasa realizująca pojedynczy rzut kością\n",
    "    \n",
    "    Atributes\n",
    "    ---------\n",
    "    sciany : int, optional\n",
    "        liczba ścian losowej kości (default is 6)\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    roll() :\n",
    "        zwraca losową wartość od 1 do liczby ścian \n",
    "    \"\"\"\n",
    "    def __init__(self, sciany: int=6):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        sciany : int\n",
    "            liczba ścian kości\n",
    "        \"\"\"\n",
    "\n",
    "        self.sciany = sciany\n",
    "\n",
    "    def roll(self):\n",
    "        '''\n",
    "        Zwraca losową liczbę naturalną od 1 do liczby ścian\n",
    "        Return\n",
    "        ------\n",
    "        losowa wartość ściany kości\n",
    "        '''\n",
    "        return randint(1,self.sciany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kosc = Kosc() # stwórz kość"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for _ in range(10): # powtórz 10 razy\n",
    "    result = kosc.roll() # rzuć kością raz\n",
    "    results.append(result) # zapisz do listy\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.3. Klasa 2 - błądzenie losowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "class RandomWalk(object):\n",
    "    \"\"\"\n",
    "    Klasa generująca błądzenie losowego w 2D\n",
    "\n",
    "    Atributes\n",
    "    ---------\n",
    "    num_points : int\n",
    "        liczba ścian losowej kości\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    fill_walk()) :\n",
    "        zwraca realizację błądzenia losowego na płaszczyźnie\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_points: int=5000):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_points : int, optional\n",
    "            liczba kroków\n",
    "        x_values : list \n",
    "            lista losowych połozen x\n",
    "            początkowo punkt 0\n",
    "        y_values : list\n",
    "            lista losowych połozen y\n",
    "            początkowo punkt 0\n",
    "        \"\"\"\n",
    "        self.num_points = num_points\n",
    "        self.x_values = [0]\n",
    "        self.y_values = [0]\n",
    "\n",
    "    def fill_walk(self):\n",
    "        '''\n",
    "        Zwraca wygenerowany przypadek bładzenia losowego\n",
    "        Return\n",
    "        ------\n",
    "        listy x_values i y_values\n",
    "        '''\n",
    "        while len(self.x_values) < self.num_points:\n",
    "            x_direction = choice([-1,1])\n",
    "            x_distance = choice([0,1,2,3,4])\n",
    "            x_step = x_direction*x_distance\n",
    "\n",
    "            y_direction = choice([-1,1])\n",
    "            y_distance = choice([0,1,2,3,4])\n",
    "            y_step = y_direction*y_distance\n",
    "\n",
    "            if x_step == 0 and y_step == 0:\n",
    "                continue\n",
    "\n",
    "            next_x = self.x_values[-1] + x_step\n",
    "            next_y = self.y_values[-1] + y_step\n",
    "\n",
    "            self.x_values.append(next_x)\n",
    "            self.y_values.append(next_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw = RandomWalk(50000)\n",
    "rw.fill_walk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "point_number = list(range(rw.num_points))\n",
    "plt.scatter(rw.x_values, rw.y_values, c=point_number, cmap=plt.cm.Blues, edgecolor='none', s=15)\n",
    "plt.scatter(0, 0, c='green', edgecolor='none', s=100)\n",
    "plt.scatter(rw.x_values[-1], rw.y_values[-1], c='red', edgecolor='none', s=100)\n",
    "plt.axis('off')\n",
    "#plt.savefig('rys1_3.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.4. Obiekty i bazy danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import Column, String, Integer\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///irysy.db')\n",
    "base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transakcje(base):\n",
    "    \"\"\"Tabela danych\"\"\"\n",
    "    __tablename__ = 'transakcje'\n",
    "    transakcja_id = Column(Integer, primary_key=True )\n",
    "    data = Column(String)\n",
    "    przedmiot_id = Column(Integer)\n",
    "    cena = Column(Integer)\n",
    "\n",
    "    def __init__(self, transakcja_id, data, przedmiot_id, cena):\n",
    "        self.transakcja_id = transakcja_id\n",
    "        self.data = data\n",
    "        self.przedmiot_id = przedmiot_id\n",
    "        self.cena = cena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.metadata.create_all(engine)\n",
    "\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "# Stworzenie nowej sesji\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(10):\n",
    "    tr = Transakcje(t, f'200{t}/05/06', t**2-t*2, 19)\n",
    "    session.add(tr)\n",
    "# zapis zmian w bazie danych\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in session.query(Transakcje).all():\n",
    "    print(s.transakcja_id, s.data, s.cena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wybrane transakcje\n",
    "for s in session.query(Transakcje).filter(Transakcje.transakcja_id>5):\n",
    "    print(s.transakcja_id, s.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.5. Obiektowoś w pakiecie Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# przykładowe dane\n",
    "dane = {\"zm1\":[4.35, 23.3, 5.34, 45.2, 5, 34.5, 23.5, 62.3, 62.7, 35.8],\n",
    "        \"zm2\":[2.3, 5.2, np.nan, 6.2, 3.4, np.nan, 3.5, 1.3, 7.4, 5.66 ], \n",
    "        \"zm3\":[\"czerwony\",\"zielony\",\"czerwony\",\"niebieski\",\"zielony\",\n",
    "               \"zielony\", \"niebieski\", \"niebieski\",\"czerwony\",\"zielony\"], \n",
    "        \"zm4\":[\"M\",\"F\",\"M\",\"M\",\"F\",\"M\",\"M\",\"F\",\"F\",\"F\"]\n",
    "        }\n",
    "df = pd.DataFrame(dane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"zm1\", \"zm2\"]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "categorical_features = [\"zm3\", \"zm4\"]\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num_trans\", numeric_transformer, numeric_features),\n",
    "    (\"cat_trans\", categorical_transformer, categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preproc\", preprocessor),\n",
    "    (\"model\", LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "y = [0,1,1,0,1,0,0,0,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(X,y, \n",
    "test_size=0.2, random_state=42)\n",
    "pipeline.fit(X_tr, y_tr)\n",
    "# jakość modelu\n",
    "score = pipeline.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(pipeline, 'your_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "              {\"preproc__num_trans__imputer__strategy\":\n",
    "              [\"mean\",\"median\"],\n",
    "               \"model__n_estimators\":[2,5,10,100,500],\n",
    "               \"model__min_samples_leaf\": [1, 0.1],\n",
    "               \"model\":[RandomForestClassifier()]},\n",
    "              {\"preproc__num_trans__imputer__strategy\":\n",
    "              [\"mean\",\"median\"],\n",
    "               \"model__C\":[0.1,1.0,10.0,100.0,1000],\n",
    "               \"model\":[LogisticRegression()]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, \n",
    "cv=3, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DelOneValueFeature(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Transformacja usuwająca zmienne, które posiadają\n",
    "    tylko jedną wartość w całej kolumnie. Takie kolumny\n",
    "    nie nadają się do modelowania. Metoda fit() wyszuka\n",
    "    wszystkie takie kolumny. Natomiast metoda transform()\n",
    "    usunie je ze zbioru danych.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.one_value_features = []\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        for feature in X.columns:\n",
    "            unikalne = X[feature].unique()\n",
    "            if len(unikalne)==1:\n",
    "                self.one_value_features.append(feature)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if not self.one_value_features:\n",
    "            return X\n",
    "        return X.drop(axis='columns',\n",
    "        columns=self.one_value_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline([\n",
    "    (\"moja_transformacja\",DelOneValueFeature()),\n",
    "    (\"preprocesser\", preprocessor), \n",
    "    (\"classifier\", LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2.fit(X_tr, y_tr)\n",
    "score2 = pipeline2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.6. Obiektowa siec neuronowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 3 * np.random.rand(100,1)\n",
    "y = 5 + 2 * X + np.random.randn(100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dodajemy 1 do każdej obserwacji \n",
    "X_b = np.c_[np.ones((100,1)),X]\n",
    "# rozwiazanie\n",
    "parametry = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "parametry\n",
    "# dla wylosowanych przeze mnie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(X,columns=['X']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb \n",
    "import pandas as pd\n",
    "\n",
    "sb.scatterplot(data = df2, x='X',y='y')\n",
    "plt.savefig('rys1_4.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sb.lmplot(data=df2, x='X',y='y', lowess=True)\n",
    "x_lin=np.linspace(0,3)\n",
    "y_lin=x_lin*parametry[1]+parametry[0]  \n",
    "plt.plot(x_lin, y_lin, color=\"red\") \n",
    "sb.scatterplot(data = df2, x='X',y='y')\n",
    "plt.savefig('rys1_5.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.1\n",
    "l_iteracji = 1000\n",
    "m = 100\n",
    "# losowe wartosci poczatkowe\n",
    "theta = np.random.randn(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoka in range(l_iteracji):\n",
    "    grad = 2/m * X_b.T.dot(X_b.dot(theta)-y)\n",
    "    theta = theta - eta * grad\n",
    "\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(units=1, input_shape=[1])\n",
    "])\n",
    "model.compile(optimizer='sgd', loss=\"mean_squared_error\")\n",
    "model.fit(X, y, epochs=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X_iris, y_iris\n",
    "dziecko = Perceptron()\n",
    "dziecko.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    \"\"\"Klasa realizująca algorytm sieci neuronowej\"\"\"\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dziecko = Perceptron()\n",
    "dziecko.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    \"\"\"Klasa realizująca algorytm sieci neuronowej\"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=10):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dziecko = Perceptron()\n",
    "dziecko.fit(X,y)\n",
    "dziecko.n_iter, dziecko.eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    \"\"\"Klasa realizująca algorytm sieci neuronowej\"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=10):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "    \n",
    "    def fit(self, X, y ):\n",
    "        self.w_ = np.zeros(1+X.shape[1])\n",
    "        self.errors_ = []\n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X,y):\n",
    "               update = self.eta*(target-self.predict(xi))\n",
    "               self.w_[1:] += update*xi\n",
    "               self.w_[0] += update\n",
    "               errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_[1:])+self.w_[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.where(self.net_input(X)>=0.0,1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dziecko_uczy_sie_irysow = Perceptron()\n",
    "dziecko_uczy_sie_irysow.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dziecko_uczy_sie_irysow.w_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dziecko_uczy_sie_irysow.errors_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_and = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y_and = np.array([-1,-1,-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_regions(X,y,classifier, resolution=0.02):\n",
    "    markers = ('s','x','o','^','v')\n",
    "    colors = ('red','blue','lightgreen','gray','cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    x1_min, x1_max = X[:,0].min() - 1, X[:,0].max()+1\n",
    "    x2_min, x2_max = X[:,1].min() -1, X[:,1].max()+1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(),xx2.max())\n",
    "\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl,0], y=X[y==cl,1],\n",
    "        alpha=0.8, c=cmap(idx), marker=markers[idx], label=cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X,y,\n",
    "classifier=dziecko_uczy_sie_irysow)\n",
    "plt.xlabel(\"dlugosc dzialki [cm]\")\n",
    "plt.ylabel(\"dlugosc platka [cm]\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig('rys1_6.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaline():\n",
    "    '''Klasyfikator  - ADAptacyjny LIniowy NEuron'''\n",
    "    def __init__(self, eta=0.01, n_iter=10):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def fit(self, X,y):\n",
    "        self.w_ = np.zeros(1+X.shape[1])\n",
    "        self.cost_ = []\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            net_input = self.net_input(X)\n",
    "            output = self.activation(X)\n",
    "            errors = (y-output)\n",
    "            self.w_[1:] += self.eta * X.T.dot(errors)\n",
    "            self.w_[0] += self.eta * errors.sum()\n",
    "            cost = (errors**2).sum() / 2.0\n",
    "            self.cost_.append(cost)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def activation(self, X):\n",
    "        return self.net_input(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.where(self.activation(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = Adaline(n_iter=20, eta=0.01)\n",
    "ad.fit(X,y)\n",
    "# otrzymane wagi\n",
    "ad.w_\n",
    "# array([-0.0259, -0.06051, 0.17152])\n",
    "# wykres granicy decyzyjnej\n",
    "plot_decision_regions(X,y,classifier=ad)\n",
    "plt.xlabel(\"dlugosc dzialki [cm]\")\n",
    "plt.ylabel(\"dlugosc platka [cm]\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig('rys1_7.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad2 = Adaline(n_iter=20, eta=0.0001)\n",
    "ad2.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad2.w_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X,y,classifier=ad2)\n",
    "plt.xlabel(\"dlugosc dzialki [cm]\")\n",
    "plt.ylabel(\"dlugosc platka [cm]\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig('rys1_8.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e1143f982d67ed63b394819c0055b556226ea2b15cfc376a81c44e9359cfc8e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
